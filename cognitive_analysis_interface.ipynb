{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naruKwf6v3mh",
        "outputId": "f5166e60-d8f1-4816-f898-5d65b767d370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, PyPDF2, pydeck, streamlit\n",
            "Successfully installed PyPDF2-3.0.1 pydeck-0.9.1 streamlit-1.44.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit PyPDF2 scikit-learn pandas matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQYNLSUuw8VK",
        "outputId": "dd7e48f1-6e27-4a78-b715-0bcd49b84243"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "# Paste the entire Streamlit app code here\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import PyPDF2\n",
        "from collections import Counter\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Cognitive Level Classifier\",\n",
        "    page_icon=\"🧠\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    text = \"\"\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "    for page_num in range(len(pdf_reader.pages)):\n",
        "        page = pdf_reader.pages[page_num]\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "\n",
        "def extract_data(text):\n",
        "\n",
        "    pattern = r'(\\d+)\\.\\s+(.*?)\\s+\\((CO\\d+)\\s+(K\\d+)\\s+-\\s+(.*?)\\)'\n",
        "    matches = re.findall(pattern, text)\n",
        "\n",
        "    data = []\n",
        "    for match in matches:\n",
        "        question_num = match[0]\n",
        "        question_text = match[1].strip()\n",
        "        course_outcome = match[2]\n",
        "        knowledge_level_code = match[3]\n",
        "        knowledge_level = match[4]\n",
        "        data.append({\n",
        "            'question_num': question_num,\n",
        "            'question_text': question_text,\n",
        "            'course_outcome': course_outcome,\n",
        "            'knowledge_level_code': knowledge_level_code,\n",
        "            'knowledge_level': knowledge_level\n",
        "        })\n",
        "\n",
        "\n",
        "    if not data:\n",
        "        alt_pattern = r'(\\d+)\\.\\s+(.*?)\\s*\\((?:CO\\d+)?(?:\\s*|\\s*,\\s*)(K\\d+)(?:\\s*-\\s*|\\s*:\\s*|\\s+)(.*?)(?:\\)|$)'\n",
        "        alt_matches = re.findall(alt_pattern, text)\n",
        "        for match in alt_matches:\n",
        "            question_num = match[0]\n",
        "            question_text = match[1].strip()\n",
        "            knowledge_level_code = match[2]\n",
        "            knowledge_level = match[3].strip()\n",
        "            data.append({\n",
        "                'question_num': question_num,\n",
        "                'question_text': question_text,\n",
        "                'course_outcome': 'Unknown',  # May be missing in alternative format\n",
        "                'knowledge_level_code': knowledge_level_code,\n",
        "                'knowledge_level': knowledge_level\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "knowledge_level_mapping = {\n",
        "    'K1': 1,  # Knowledge\n",
        "    'K2': 2,  # Comprehension\n",
        "    'K3': 3,  # Application\n",
        "    'K4': 4,  # Analysis\n",
        "    'K5': 5,  # Evaluation\n",
        "    'K6': 6   # Creation\n",
        "}\n",
        "\n",
        "knowledge_level_descriptions = {\n",
        "    'K1': 'Knowledge',\n",
        "    'K2': 'Comprehension',\n",
        "    'K3': 'Application',\n",
        "    'K4': 'Analysis',\n",
        "    'K5': 'Evaluation',\n",
        "    'K6': 'Creation'\n",
        "}\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Preprocess text for better feature extraction\"\"\"\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def train_model(train_pdf):\n",
        "    \"\"\"Train the model from uploaded PDF\"\"\"\n",
        "\n",
        "    train_text = extract_text_from_pdf(train_pdf)\n",
        "\n",
        "\n",
        "    train_df = extract_data(train_text)\n",
        "\n",
        "    if train_df.empty:\n",
        "        st.error(\"No matching data found in the training PDF. Check the pattern or PDF content.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    st.success(f\"Extracted {len(train_df)} questions from training data\")\n",
        "\n",
        "\n",
        "    class_counts = Counter(train_df['knowledge_level_code'])\n",
        "\n",
        "\n",
        "    train_df['knowledge_level_num'] = train_df['knowledge_level_code'].apply(lambda x: knowledge_level_mapping.get(x, 0))\n",
        "\n",
        "\n",
        "    train_df['processed_text'] = train_df['question_text'].apply(preprocess_text)\n",
        "\n",
        "\n",
        "    X = train_df['processed_text']\n",
        "    y = train_df['knowledge_level_code']\n",
        "\n",
        "\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        stop_words='english',\n",
        "        max_features=300,\n",
        "        ngram_range=(1, 2),\n",
        "        min_df=2,\n",
        "        max_df=0.95\n",
        "    )\n",
        "    X_features = vectorizer.fit_transform(X)\n",
        "\n",
        "\n",
        "    min_class_count = min(class_counts.values())\n",
        "\n",
        "\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        random_state=42,\n",
        "        class_weight='balanced'\n",
        "    )\n",
        "    model.fit(X_features, y)\n",
        "\n",
        "\n",
        "    y_pred = model.predict(X_features)\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    report = classification_report(y, y_pred, output_dict=True)\n",
        "\n",
        "    return model, vectorizer, train_df, accuracy, report\n",
        "\n",
        "def predict_cognitive_level(model, vectorizer, question_text):\n",
        "    \"\"\"Predict the cognitive level of a given question\"\"\"\n",
        "    if not model or not vectorizer:\n",
        "        return None\n",
        "\n",
        "\n",
        "    processed_text = preprocess_text(question_text)\n",
        "\n",
        "    question_features = vectorizer.transform([processed_text])\n",
        "\n",
        "\n",
        "    prediction = model.predict(question_features)[0]\n",
        "    confidence = model.predict_proba(question_features)[0]\n",
        "\n",
        "\n",
        "    predicted_class_index = list(model.classes_).index(prediction)\n",
        "    confidence_score = confidence[predicted_class_index]\n",
        "\n",
        "\n",
        "    predicted_level = knowledge_level_descriptions.get(prediction, \"Unknown\")\n",
        "\n",
        "    return {\n",
        "        'question': question_text,\n",
        "        'predicted_code': prediction,\n",
        "        'predicted_level': predicted_level,\n",
        "        'confidence': confidence_score\n",
        "    }\n",
        "\n",
        "def predict_from_pdf(model, vectorizer, pdf_file):\n",
        "    \"\"\"Extract questions from a PDF and predict their cognitive levels\"\"\"\n",
        "    if not model or not vectorizer:\n",
        "        st.error(\"Model not trained\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    pdf_text = extract_text_from_pdf(pdf_file)\n",
        "\n",
        "\n",
        "    pattern = r'(\\d+)\\.\\s+(.*?)(?=\\(\\w+\\s+\\w+|\\d+\\.|$)'\n",
        "    matches = re.findall(pattern, pdf_text)\n",
        "\n",
        "    if not matches:\n",
        "        st.warning(\"No questions found using structured pattern. Using simple line extraction.\")\n",
        "        # Fall back to simple line-by-line extraction\n",
        "        lines = [line.strip() for line in pdf_text.split('\\n') if line.strip()]\n",
        "        questions = [line for line in lines if re.match(r'^\\d+\\.', line)]\n",
        "    else:\n",
        "        questions = [match[1].strip() for match in matches]\n",
        "\n",
        "    if not questions:\n",
        "        st.error(\"No questions found in the PDF.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    predictions = []\n",
        "    for question in questions:\n",
        "        if len(question) > 10:  # Minimum length to avoid fragments\n",
        "            pred = predict_cognitive_level(model, vectorizer, question)\n",
        "            predictions.append(pred)\n",
        "\n",
        "    # Create a DataFrame for better visualization\n",
        "    pred_df = pd.DataFrame(predictions)\n",
        "    st.success(f\"Predicted cognitive levels for {len(pred_df)} questions\")\n",
        "\n",
        "    return pred_df\n",
        "\n",
        "def plot_knowledge_level_distribution(df):\n",
        "    \"\"\"Plot the distribution of knowledge levels\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    sns.countplot(x='knowledge_level_code', data=df, ax=ax)\n",
        "    ax.set_title('Distribution of Knowledge Levels in the Training Data')\n",
        "    ax.set_xlabel('Knowledge Level')\n",
        "    ax.set_ylabel('Count')\n",
        "    return fig\n",
        "\n",
        "def plot_feature_importance(model, vectorizer):\n",
        "    \"\"\"Plot feature importance\"\"\"\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False).head(15)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    sns.barplot(x='importance', y='feature', data=feature_importance, ax=ax)\n",
        "    ax.set_title('Top 15 Important Words for Predicting Knowledge Level')\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def get_table_download_link(df, filename, text):\n",
        "    \"\"\"Generate a link to download the dataframe as a CSV file\"\"\"\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode()).decode()\n",
        "    href = f'<a href=\"data:file/csv;base64,{b64}\" download=\"{filename}\">📥 {text}</a>'\n",
        "    return href\n",
        "\n",
        "def main():\n",
        "    st.title(\"🧠 Cognitive Level Classifier\")\n",
        "    st.markdown(\"\"\"\n",
        "    This app classifies questions based on Bloom's Taxonomy cognitive levels:\n",
        "    - **K1**: Knowledge - Recalling facts, terms, basic concepts\n",
        "    - **K2**: Comprehension - Understanding the meaning of information\n",
        "    - **K3**: Application - Using knowledge in new situations\n",
        "    - **K4**: Analysis - Breaking down information into parts\n",
        "    - **K5**: Evaluation - Making judgments based on criteria\n",
        "    - **K6**: Creation - Creating new ideas or ways of viewing things\n",
        "    \"\"\")\n",
        "\n",
        "    # Initialize session state variables if they don't exist\n",
        "    if 'model' not in st.session_state:\n",
        "        st.session_state.model = None\n",
        "    if 'vectorizer' not in st.session_state:\n",
        "        st.session_state.vectorizer = None\n",
        "    if 'accuracy' not in st.session_state:\n",
        "        st.session_state.accuracy = None\n",
        "    if 'report' not in st.session_state:\n",
        "        st.session_state.report = None\n",
        "    if 'train_df' not in st.session_state:\n",
        "        st.session_state.train_df = None\n",
        "\n",
        "    # Create tabs\n",
        "    tab1, tab2, tab3, tab4 = st.tabs([\"Train Model\", \"Predict Single Question\", \"Predict From PDF\", \"Model Analysis\"])\n",
        "\n",
        "    with tab1:\n",
        "        st.header(\"Train your model\")\n",
        "        st.markdown(\"\"\"\n",
        "        Upload a training PDF containing questions tagged with knowledge levels (K1-K6).\n",
        "        The PDF should follow formats like: `1. Question text (CO1 K2 - Comprehension)`\n",
        "        \"\"\")\n",
        "\n",
        "        train_pdf = st.file_uploader(\"Upload Training PDF\", type=['pdf'], key='train_pdf')\n",
        "\n",
        "        train_col1, train_col2 = st.columns(2)\n",
        "        with train_col1:\n",
        "            if st.button(\"Train Model\", type=\"primary\"):\n",
        "                if train_pdf is not None:\n",
        "                    with st.spinner(\"Training model...\"):\n",
        "                        model, vectorizer, train_df, accuracy, report = train_model(train_pdf)\n",
        "                        if model is not None:\n",
        "                            st.session_state.model = model\n",
        "                            st.session_state.vectorizer = vectorizer\n",
        "                            st.session_state.train_df = train_df\n",
        "                            st.session_state.accuracy = accuracy\n",
        "                            st.session_state.report = report\n",
        "                            st.success(f\"Model trained successfully! Accuracy: {accuracy:.2f}\")\n",
        "                else:\n",
        "                    st.error(\"Please upload a training PDF\")\n",
        "\n",
        "        with train_col2:\n",
        "            if st.session_state.model is not None:\n",
        "                st.success(\"Model is trained and ready for predictions!\")\n",
        "                if st.session_state.train_df is not None:\n",
        "                    st.write(f\"Training data: {len(st.session_state.train_df)} questions\")\n",
        "                    if st.checkbox(\"Show training data sample\"):\n",
        "                        st.dataframe(st.session_state.train_df[['question_num', 'question_text', 'knowledge_level_code', 'knowledge_level']].head(10))\n",
        "\n",
        "    with tab2:\n",
        "        st.header(\"Predict Knowledge Level for a Single Question\")\n",
        "\n",
        "        # Check if model is trained\n",
        "        if st.session_state.model is None:\n",
        "            st.warning(\"Please train the model first in the 'Train Model' tab\")\n",
        "        else:\n",
        "            question_text = st.text_area(\"Enter your question:\", height=100)\n",
        "\n",
        "            if st.button(\"Predict\", key=\"predict_single\"):\n",
        "                if question_text:\n",
        "                    with st.spinner(\"Predicting...\"):\n",
        "                        prediction = predict_cognitive_level(st.session_state.model, st.session_state.vectorizer, question_text)\n",
        "\n",
        "                        # Display prediction with color coding\n",
        "                        col1, col2, col3 = st.columns(3)\n",
        "                        with col1:\n",
        "                            st.metric(\"Predicted Level\", f\"{prediction['predicted_code']} - {prediction['predicted_level']}\")\n",
        "                        with col2:\n",
        "                            st.metric(\"Confidence\", f\"{prediction['confidence']:.2f}\")\n",
        "\n",
        "                        # Knowledge level explanation\n",
        "                        level_explanations = {\n",
        "                            'K1': \"Knowledge level question - Focuses on recall of facts, terms, or basic concepts\",\n",
        "                            'K2': \"Comprehension level question - Tests understanding of meaning and interpretation\",\n",
        "                            'K3': \"Application level question - Requires using knowledge in a new context or situation\",\n",
        "                            'K4': \"Analysis level question - Involves breaking down information and understanding relationships\",\n",
        "                            'K5': \"Evaluation level question - Requires making judgments based on criteria\",\n",
        "                            'K6': \"Creation level question - Involves creating new ideas, products, or ways of viewing things\"\n",
        "                        }\n",
        "\n",
        "                        st.info(level_explanations.get(prediction['predicted_code'], \"Unknown level\"))\n",
        "\n",
        "                        # Suggestion for improvement if confidence is low\n",
        "                        if prediction['confidence'] < 0.7:\n",
        "                            st.warning(\"Low confidence prediction. Consider rewording the question for clearer classification.\")\n",
        "                else:\n",
        "                    st.error(\"Please enter a question\")\n",
        "\n",
        "    with tab3:\n",
        "        st.header(\"Predict Knowledge Levels from PDF\")\n",
        "\n",
        "        # Check if model is trained\n",
        "        if st.session_state.model is None:\n",
        "            st.warning(\"Please train the model first in the 'Train Model' tab\")\n",
        "        else:\n",
        "            test_pdf = st.file_uploader(\"Upload PDF with questions to classify\", type=['pdf'], key='test_pdf')\n",
        "\n",
        "            if st.button(\"Predict from PDF\", key=\"predict_pdf\"):\n",
        "                if test_pdf is not None:\n",
        "                    with st.spinner(\"Extracting questions and predicting...\"):\n",
        "                        predictions_df = predict_from_pdf(st.session_state.model, st.session_state.vectorizer, test_pdf)\n",
        "\n",
        "                        if not predictions_df.empty:\n",
        "                            # Display results\n",
        "                            st.dataframe(predictions_df)\n",
        "\n",
        "                            # Download link for predictions\n",
        "                            st.markdown(get_table_download_link(predictions_df, \"predictions.csv\", \"Download predictions as CSV\"), unsafe_allow_html=True)\n",
        "\n",
        "                            # Summary statistics\n",
        "                            st.subheader(\"Summary Statistics\")\n",
        "                            level_counts = predictions_df['predicted_code'].value_counts()\n",
        "                            col1, col2 = st.columns(2)\n",
        "\n",
        "                            with col1:\n",
        "                                st.write(\"Distribution of predicted levels:\")\n",
        "                                st.dataframe(pd.DataFrame({\n",
        "                                    'Level': level_counts.index,\n",
        "                                    'Count': level_counts.values,\n",
        "                                    'Percentage': (level_counts.values / level_counts.sum() * 100).round(1)\n",
        "                                }))\n",
        "\n",
        "                            with col2:\n",
        "                                fig, ax = plt.subplots()\n",
        "                                ax.pie(level_counts.values, labels=level_counts.index, autopct='%1.1f%%')\n",
        "                                ax.set_title('Distribution of Predicted Knowledge Levels')\n",
        "                                st.pyplot(fig)\n",
        "                else:\n",
        "                    st.error(\"Please upload a PDF\")\n",
        "\n",
        "    with tab4:\n",
        "        st.header(\"Model Analysis\")\n",
        "\n",
        "        if st.session_state.model is None:\n",
        "            st.warning(\"Please train the model first in the 'Train Model' tab\")\n",
        "        else:\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                st.subheader(\"Training Accuracy\")\n",
        "                st.metric(\"Overall Accuracy\", f\"{st.session_state.accuracy:.2f}\")\n",
        "\n",
        "                st.subheader(\"Class-wise Performance\")\n",
        "                report_df = pd.DataFrame(st.session_state.report).T\n",
        "                st.dataframe(report_df.iloc[:-3][['precision', 'recall', 'f1-score']].round(2))\n",
        "\n",
        "            with col2:\n",
        "                if st.session_state.train_df is not None:\n",
        "                    st.subheader(\"Knowledge Level Distribution\")\n",
        "                    fig = plot_knowledge_level_distribution(st.session_state.train_df)\n",
        "                    st.pyplot(fig)\n",
        "\n",
        "            st.subheader(\"Feature Importance\")\n",
        "            if st.session_state.model is not None and st.session_state.vectorizer is not None:\n",
        "                fig = plot_feature_importance(st.session_state.model, st.session_state.vectorizer)\n",
        "                st.pyplot(fig)\n",
        "\n",
        "            # Display some example questions for each level\n",
        "            st.subheader(\"Example Questions by Level\")\n",
        "            if st.session_state.train_df is not None:\n",
        "                for level in sorted(st.session_state.train_df['knowledge_level_code'].unique()):\n",
        "                    with st.expander(f\"{level} - {knowledge_level_descriptions.get(level, 'Unknown')}\"):\n",
        "                        examples = st.session_state.train_df[st.session_state.train_df['knowledge_level_code'] == level]['question_text'].head(3).tolist()\n",
        "                        for i, example in enumerate(examples, 1):\n",
        "                            st.write(f\"{i}. {example}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAtsnG20xSwE",
        "outputId": "e29919dd-b279-4168-ccba-06e2b5e4891d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.141.247.186"
          ]
        }
      ],
      "source": [
        "!curl https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxQ-ABn-xD8I",
        "outputId": "e86b8a9f-8498-47f9-a87d-df22ae549898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "added 22 packages in 4s\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0Kyour url is: https://thick-olives-repeat.loca.lt\n"
          ]
        }
      ],
      "source": [
        "# Install localtunnel to expose the Streamlit app\n",
        "!npm install -g localtunnel\n",
        "\n",
        "# Run Streamlit in the background and create a tunnel\n",
        "!streamlit run app.py &>/content/logs.txt & sleep 5 && lt --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}